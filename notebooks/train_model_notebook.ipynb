{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29be347c",
   "metadata": {},
   "source": [
    "# Train Notebook — Parking Slot Occupancy Classifier\n",
    "\n",
    "This notebook converts your `train_model.py` training script into a **well-organized Jupyter notebook** with explanatory markdown cells and runnable code cells. Use this to step through data loading, model creation, training and evaluation **interactively**.\n",
    "\n",
    "**Notes**\n",
    "- The notebook mirrors the existing `train_model.py` logic but breaks it into small cells with explanations.\n",
    "- Training can be run cell-by-cell. On a laptop it's recommended to use small epochs for testing first.\n",
    "- Save the notebook and run in your `parking-project` conda environment (the same `parking-ai` env you used).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf975d4f",
   "metadata": {},
   "source": [
    "## 1) Imports and configuration\n",
    "This cell imports required libraries and sets constants (data paths, model dir)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff111e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f7b3e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook configured. DATA_ROOT = /Users/thrinath/thrinath_files/INT395/parking-project/data/raw MODEL_DIR = /Users/thrinath/thrinath_files/INT395/parking-project/models/trained\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "from glob import glob\n",
    "from typing import List, Tuple\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms, models\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Paths (adjust if needed)\n",
    "DATA_ROOT = \"/Users/thrinath/thrinath_files/INT395/parking-project/data/raw\"\n",
    "MODEL_DIR = \"/Users/thrinath/thrinath_files/INT395/parking-project/models/trained\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Notebook configured. DATA_ROOT =\", DATA_ROOT, \"MODEL_DIR =\", MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5a9fac",
   "metadata": {},
   "source": [
    "## 2) Inspect dataset structure\n",
    "Run the cell below to quickly inspect number of slots and counts per class. This helps confirm your `Emp` -> `empty` rename worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7aafd7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 slot folders\n",
      "\n",
      "A1: empty=147, occupied=66\n",
      "A2: empty=147, occupied=66\n",
      "A3: empty=147, occupied=66\n",
      "B1: empty=147, occupied=66\n",
      "B2: empty=147, occupied=66\n",
      "B3: empty=147, occupied=66\n"
     ]
    }
   ],
   "source": [
    "# Quick dataset inspection\n",
    "from pathlib import Path\n",
    "root = Path(DATA_ROOT)\n",
    "slot_dirs = sorted([d for d in root.iterdir() if d.is_dir()])\n",
    "print(f\"Found {len(slot_dirs)} slot folders\\n\")\n",
    "for sd in slot_dirs:\n",
    "    empty_count = len(list((sd / 'empty').glob('*'))) if (sd / 'empty').exists() else 0\n",
    "    occ_count = len(list((sd / 'occupied').glob('*'))) if (sd / 'occupied').exists() else 0\n",
    "    print(f\"{sd.name}: empty={empty_count}, occupied={occ_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53a4e02",
   "metadata": {},
   "source": [
    "## 3) Dataset class\n",
    "This cell defines the PyTorch `Dataset` used to load images and apply transforms. It mirrors the logic in `train_model.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "017fe7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParkingSlotDataset defined.\n"
     ]
    }
   ],
   "source": [
    "class ParkingSlotDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 root_dir: str,\n",
    "                 classes: Tuple[str, ...] = (\"empty\", \"occupied\"),\n",
    "                 img_size: int = 224,\n",
    "                 train: bool = True):\n",
    "        self.root_dir = root_dir\n",
    "        self.classes = classes\n",
    "        self.class_to_idx = {c: i for i, c in enumerate(classes)}\n",
    "        self.img_size = img_size\n",
    "\n",
    "        # Collect all image paths and labels\n",
    "        self.samples: List[Tuple[str, int]] = []\n",
    "\n",
    "        for slot_dir in sorted(os.listdir(root_dir)):\n",
    "            slot_path = os.path.join(root_dir, slot_dir)\n",
    "            if not os.path.isdir(slot_path):\n",
    "                continue\n",
    "            for cls in classes:\n",
    "                cls_dir = os.path.join(slot_path, cls)\n",
    "                if not os.path.isdir(cls_dir):\n",
    "                    continue\n",
    "                for ext in (\"*.jpg\", \"*.jpeg\", \"*.png\"):\n",
    "                    for img_path in glob(os.path.join(cls_dir, ext)):\n",
    "                        self.samples.append((img_path, self.class_to_idx[cls]))\n",
    "\n",
    "        if not self.samples:\n",
    "            raise RuntimeError(f\"No images found in {root_dir} for classes {classes}\")\n",
    "\n",
    "        # Basic transforms: augmentation for train, light for val\n",
    "        if train:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((img_size, img_size)),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomRotation(5),\n",
    "                transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225]),\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((img_size, img_size)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225]),\n",
    "            ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        img_path, label = self.samples[idx]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "# Simple smoke test: create dataset with train=True and print sample count (do not load images yet)\n",
    "print('ParkingSlotDataset defined.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43a53df",
   "metadata": {},
   "source": [
    "## 4) Build datasets and dataloaders\n",
    "This cell creates train/validation split and dataloaders. It re-uses the dataset defined above. Adjust `img_size`, `batch_size`, and `val_split` as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab03ee08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 1018, Val samples: 254\n",
      "Batch X shape: torch.Size([16, 3, 224, 224]) Batch y shape: torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "# Config - change as needed for quick runs\n",
    "img_size = 224\n",
    "batch_size = 16   # smaller batch on laptop if needed\n",
    "val_split = 0.2\n",
    "shuffle = True\n",
    "\n",
    "# Build full dataset (train transforms by default)\n",
    "full_dataset = ParkingSlotDataset(root_dir=DATA_ROOT, img_size=img_size, train=True)\n",
    "\n",
    "# Compute sizes\n",
    "val_size = int(len(full_dataset) * val_split)\n",
    "train_size = len(full_dataset) - val_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "# Rebuild val_dataset with deterministic (no augment) transforms using selected indices\n",
    "val_indices = train_dataset.indices if hasattr(train_dataset, 'indices') else None\n",
    "# Note: random_split returns Subset with .indices attribute; but careful: train_dataset is a Subset.\n",
    "val_indices = val_dataset.indices if hasattr(val_dataset, 'indices') else range(len(val_dataset))\n",
    "val_samples = [full_dataset.samples[i] for i in val_indices]\n",
    "val_dataset = ParkingSlotDataset(root_dir=DATA_ROOT, img_size=img_size, train=False)\n",
    "val_dataset.samples = val_samples\n",
    "\n",
    "print(f'Train samples: {len(train_dataset)}, Val samples: {len(val_dataset)}')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "# Show a batch shape\n",
    "for xb, yb in train_loader:\n",
    "    print('Batch X shape:', xb.shape, 'Batch y shape:', yb.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3093c4be",
   "metadata": {},
   "source": [
    "## 5) Create model and helper functions\n",
    "This cell creates the MobileNetV3 small model, sets device, and provides helper functions for saving/loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c44172bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Model created. Number of parameters: 1519906\n"
     ]
    }
   ],
   "source": [
    "def create_model(num_classes: int = 2):\n",
    "    model = models.mobilenet_v3_small(weights=models.MobileNet_V3_Small_Weights.DEFAULT)\n",
    "    in_features = model.classifier[3].in_features\n",
    "    model.classifier[3] = nn.Linear(in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "def get_device():\n",
    "    if torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "device = get_device()\n",
    "print('Using device:', device)\n",
    "\n",
    "model = create_model(num_classes=2).to(device)\n",
    "print('Model created. Number of parameters:', sum(p.numel() for p in model.parameters()))\n",
    "\n",
    "def save_model(model, path):\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'class_to_idx': {'empty': 0, 'occupied': 1},\n",
    "        'img_size': img_size,\n",
    "    }, path)\n",
    "    print('Model saved to', path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218ddcf6",
   "metadata": {},
   "source": [
    "## 6) Training loop\n",
    "This cell contains a training loop. **Be careful** running it — it will train the model. For quick testing set `epochs=1` and small batch sizes. The code is the same as in your script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fab150c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n[INFO] Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Train loss: 0.0946, acc: 0.9686\n",
      "[INFO] Val   loss: 0.0666, acc: 0.9921\n",
      "Model saved to /Users/thrinath/thrinath_files/INT395/parking-project/models/trained/slot_classifier_best.pth\n",
      "[INFO] New best model saved -> /Users/thrinath/thrinath_files/INT395/parking-project/models/trained/slot_classifier_best.pth (val_acc=0.9921)\n",
      "\\n[INFO] Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Train loss: 0.0435, acc: 0.9921\n",
      "[INFO] Val   loss: 0.0518, acc: 0.9921\n",
      "\\n[INFO] Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Train loss: 0.0443, acc: 0.9902\n",
      "[INFO] Val   loss: 0.3580, acc: 0.9803\n",
      "Training finished. Best val acc: 0.9921259842519685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in tqdm(loader, desc=\"Train\", leave=False):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, preds = outputs.max(1)\n",
    "        correct += preds.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def eval_one_epoch(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc=\"Val  \", leave=False):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, preds = outputs.max(1)\n",
    "            correct += preds.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# Training runner (configure parameters here)\n",
    "epochs = 3\n",
    "lr = 1e-3\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "best_val_acc = 0.0\n",
    "best_model_path = os.path.join(MODEL_DIR, \"slot_classifier_best.pth\")\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    print(f\"\\\\n[INFO] Epoch {epoch}/{epochs}\")\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc = eval_one_epoch(model, val_loader, criterion, device)\n",
    "    print(f\"[INFO] Train loss: {train_loss:.4f}, acc: {train_acc:.4f}\")\n",
    "    print(f\"[INFO] Val   loss: {val_loss:.4f}, acc: {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        save_model(model, best_model_path)\n",
    "        print(f\"[INFO] New best model saved -> {best_model_path} (val_acc={val_acc:.4f})\")\n",
    "\n",
    "print('Training finished. Best val acc:', best_val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71f4160",
   "metadata": {},
   "source": [
    "## 7) Save / Load model\n",
    "If you trained the model above, the `save_model()` call saved the checkpoint. Use this cell to load the model weights for inference later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b95e0387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /Users/thrinath/thrinath_files/INT395/parking-project/models/trained/slot_classifier_best.pth\n"
     ]
    }
   ],
   "source": [
    "# Load saved checkpoint (example)\n",
    "ckpt_path = os.path.join(MODEL_DIR, \"slot_classifier_best.pth\")\n",
    "if os.path.exists(ckpt_path):\n",
    "    chk = torch.load(ckpt_path, map_location=device)\n",
    "    model_loaded = create_model(num_classes=2).to(device)\n",
    "    model_loaded.load_state_dict(chk['model_state_dict'])\n",
    "    model_loaded.eval()\n",
    "    print('Loaded model from', ckpt_path)\n",
    "else:\n",
    "    print('No checkpoint found at', ckpt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d156e96",
   "metadata": {},
   "source": [
    "## 8) Notes and next steps\n",
    "- If training is slow on CPU, reduce `img_size` or `batch_size`.\n",
    "- Consider `torch.compile()` (PyTorch 2+) for speedups if available.\n",
    "- If you want, I can also convert this notebook into a cleaned PDF-ready report or wire it into your repo as `notebooks/training_experiments.ipynb`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "parking-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
